{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final tag prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/15nisha/Tag_prediction/blob/main/final_tag_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7dOe_Ng2-ii"
      },
      "source": [
        ""
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cELTpqtYu46K"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv \n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import ToktokTokenizer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJPg0KIMvPbI"
      },
      "source": [
        "**importing file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6adfkwDvG2v",
        "outputId": "c82990a2-2840-4d10-9ea8-eef05f3d7db6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sso5SMlqvJ5b"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/tag_recommendation/data.csv\")"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDEAxjjPvTpI"
      },
      "source": [
        "**Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wafkBt8hvZnw",
        "outputId": "29c8adf7-cb5a-47cc-ed26-e90b33ab3d6d"
      },
      "source": [
        "# load stop words\n",
        "# import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_word = stopwords.words('english')\n",
        "stop = stopwords.words('english')"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpOsaEjyvicQ"
      },
      "source": [
        "def cleanig_data(dataset):\n",
        "  ''' function to clean text data . It will remove all special char , HTML tags and null values'''\n",
        "  # removing 'Unnamed: 0' , which is present in dataset bcz of no use.\n",
        "  dataset.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  # removing nan values\n",
        "  dataset = dataset.dropna()\n",
        "  # changing all description text into lower form\n",
        "  dataset['description'] = dataset['description'].str.lower()\n",
        "  # changing all tags text into lower form\n",
        "  dataset['tags'] = dataset['tags'].str.lower()\n",
        "\n",
        "  def cleanHtml(sentence):\n",
        "    ''' It cleans all HTML tags '''\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
        "    return cleantext\n",
        "  def cleanPunc(sentence): \n",
        "    '''function to clean the word of any punctuation or special characters'''\n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    cleaned = cleaned.strip()\n",
        "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
        "    return cleaned\n",
        "  def keepAlpha(sentence):\n",
        "    ''' only keeping words with no special character'''\n",
        "    alpha_sent = \"\"\n",
        "    for word in sentence.split():\n",
        "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
        "        alpha_sent += alpha_word\n",
        "        alpha_sent += \" \"\n",
        "    alpha_sent = alpha_sent.strip()\n",
        "    return alpha_sent\n",
        "  \n",
        "  token=ToktokTokenizer()\n",
        "  lemma=WordNetLemmatizer()\n",
        "\n",
        "  def lemitizeWords(text):\n",
        "    ''' function to apply lemmatizer on text'''\n",
        "    words=token.tokenize(text)\n",
        "    listLemma=[]\n",
        "    for w in words:\n",
        "        x=lemma.lemmatize(w, pos=\"v\")\n",
        "        listLemma.append(x)\n",
        "    return ' '.join(map(str, listLemma))\n",
        "  # applying all defined fuction on dataset columns\n",
        "  dataset['description'] = dataset['description'].apply(cleanHtml)\n",
        "  dataset['description'] = dataset['description'].apply(cleanPunc)\n",
        "  dataset['description'] = dataset['description'].apply(keepAlpha)  \n",
        "  dataset['description'] = dataset['description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "  dataset['description'] = dataset['description'].apply(lambda x: lemitizeWords(x))\n",
        "  # returning cleaned dataset\n",
        "  return dataset"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAACZ0YXv18W"
      },
      "source": [
        "# calling function on uncleaned dataset\n",
        "data_result = cleanig_data(data)\n"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyaQoD4Yv6vh"
      },
      "source": [
        "**Tag Processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzzDKk86aajz"
      },
      "source": [
        "# split tags in space\n",
        "data_result['new_tags'] = data_result[\"tags\"].apply(lambda x: x.split())"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aYMxhvkaaUb"
      },
      "source": [
        "# add all tags\n",
        "all_tags = [item for sublist in data_result['new_tags'].values for item in sublist]"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjVjKWMRZaOb"
      },
      "source": [
        "# copying cleaned dataset into cleaned_data dataframe\n",
        "cleaned_data = data_result.copy()"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "xcvafWheemc8",
        "outputId": "4efeeb24-95b2-4477-9537-1f8b4bab7c67"
      },
      "source": [
        "# printing some part of dataset\n",
        "cleaned_data.head()"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tags</th>\n",
              "      <th>description</th>\n",
              "      <th>new_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>licence-needed supervising-job 5-plus-years-ex...</td>\n",
              "      <td>company employer midstream service provider on...</td>\n",
              "      <td>[licence-needed, supervising-job, 5-plus-years...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2-4-years-experience-needed salary full-time-job</td>\n",
              "      <td>icr staff accept resume industrial maintenance...</td>\n",
              "      <td>[2-4-years-experience-needed, salary, full-tim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>part-time-job</td>\n",
              "      <td>great position right person healthcareseeker c...</td>\n",
              "      <td>[part-time-job]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>licence-needed</td>\n",
              "      <td>large multi specialty health center expand adu...</td>\n",
              "      <td>[licence-needed]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5-plus-years-experience-needed full-time-job b...</td>\n",
              "      <td>job purpose account director responsible manag...</td>\n",
              "      <td>[5-plus-years-experience-needed, full-time-job...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                tags  ...                                           new_tags\n",
              "0  licence-needed supervising-job 5-plus-years-ex...  ...  [licence-needed, supervising-job, 5-plus-years...\n",
              "1   2-4-years-experience-needed salary full-time-job  ...  [2-4-years-experience-needed, salary, full-tim...\n",
              "2                                      part-time-job  ...                                    [part-time-job]\n",
              "3                                     licence-needed  ...                                   [licence-needed]\n",
              "4  5-plus-years-experience-needed full-time-job b...  ...  [5-plus-years-experience-needed, full-time-job...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC4z2xF6ezBF",
        "outputId": "577d80ef-eb69-41a0-b619-d79bfddb14ee"
      },
      "source": [
        "cleaned_data.shape"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3504, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epVBraKnwFDI"
      },
      "source": [
        "**train - test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZAyZZPqjoN6"
      },
      "source": [
        "# Defining X and y\n",
        "X = cleaned_data['description']\n",
        "y = cleaned_data['new_tags']"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqb2_hAPdRqL"
      },
      "source": [
        ""
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRO09AQJwebR"
      },
      "source": [
        "**Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da6bb2fDau2K"
      },
      "source": [
        "# encoding MultiLabelBinarizer for dependent lables\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html\n",
        "mulitlabel_binarizer = MultiLabelBinarizer()\n",
        "y_bin = mulitlabel_binarizer.fit_transform(y)"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf2Y653Gaxur"
      },
      "source": [
        "# printin number of classes in y or tags\n",
        "classes = mulitlabel_binarizer.classes_"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrxb72eha25W",
        "outputId": "7a825efd-2d70-4e36-ce9f-338943ae1893"
      },
      "source": [
        "classes"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1-year-experience-needed', '2-4-years-experience-needed',\n",
              "       '5-plus-years-experience-needed', 'associate-needed',\n",
              "       'bs-degree-needed', 'full-time-job', 'hourly-wage',\n",
              "       'licence-needed', 'ms-or-phd-needed', 'part-time-job', 'salary',\n",
              "       'supervising-job'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR66vsvJa-LP"
      },
      "source": [
        "# encoding independent labels or descriptions\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "vectorizer = TfidfVectorizer(analyzer = 'word',\n",
        "                                       min_df=0.0,\n",
        "                                       max_df = 1.0,\n",
        "                                       strip_accents = None,\n",
        "                                       encoding = 'utf-8', \n",
        "                                       preprocessor=None,\n",
        "                                       max_features=1000)\n",
        "\n",
        "multilabel_x_data = vectorizer.fit_transform(X)"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUAjUx3nvQUV"
      },
      "source": [
        "# splitting encoded x and y into X_train ,X_test,y_test,y_train with train-test ratio of 70:30\n",
        "X_train, X_test, y_train, y_test = train_test_split(multilabel_x_data, y_bin, test_size=0.3,random_state=123)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UdQZMYmv7R2",
        "outputId": "bcb689ab-11d3-42de-e824-f3cb0e6c33c0"
      },
      "source": [
        "# printing shape of X-train , X-test ,y-train,y-test\n",
        "print(\"Dimensions of train data X:\",X_train.shape, \"Y :\",y_train.shape)\n",
        "print(\"Dimensions of test data X:\",X_test.shape,\"Y:\",y_test.shape)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of train data X: (2452, 1000) Y : (2452, 12)\n",
            "Dimensions of test data X: (1052, 1000) Y: (1052, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_1Ut5szzfh6"
      },
      "source": [
        "**Training Model with logistic regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJclXbinzhdn"
      },
      "source": [
        "# now taining data with Onevsrest classifier technique using logistic regression algorithm\n",
        "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.00001, penalty='l1'))\n",
        "# fitting X_train,y_train on classifier defined above\n",
        "classifier.fit(X_train,y_train )\n",
        "# predicting y value by giving X_test as input\n",
        "predictions = classifier.predict (X_test)\n",
        "# predicting y value by giving X_train as input\n",
        "predictions_train = classifier.predict (X_train)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-iUCxCR0xGX"
      },
      "source": [
        "# assigning y_test to y_true\n",
        "y_true = y_test\n",
        "# assigning predicted y value of X_test to y_logits\n",
        "y_logits = predictions"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GRruPhV02ZF"
      },
      "source": [
        "#  '''it is computing fraction of equality of two array'''\n",
        "def result_check(x, y):\n",
        "  count = 0\n",
        "  for i in range(len(x)):\n",
        "    if x[i] == y[i]:\n",
        "      count += 1\n",
        "  result = count / len(x)\n",
        "  return result"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akrFMgFi059U"
      },
      "source": [
        "# https://stackoverflow.com/questions/46799261/how-to-create-an-exact-match-eval-metric-op-for-tensorflow\n",
        "def subset_accuracy(y_true,y_predict,threshold):\n",
        "  ''' it is computing accuracy of model on the basis of , equality fraction between true values and prediction values '''\n",
        "  count = 0\n",
        "  for j in range(len(y_true)):\n",
        "    if result_check(y_true[j] , y_predict[j]) >= threshold:\n",
        "      count = count + 1\n",
        "  accuracy = count / len(y_true)\n",
        "  return accuracy\n"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-HQPLhV1Cp5",
        "outputId": "2db78181-41d5-4006-8406-1e5d3b5a7931"
      },
      "source": [
        "# giving some set of equality fraction and findin accuracy\n",
        "threshold_list = [1,.9,.8,.7,.6,.5]\n",
        "for i in threshold_list:\n",
        "  print(f'for threshold {i} accuracy is = ',subset_accuracy(y_true,y_logits,threshold=i))"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for threshold 1 accuracy is =  0.12167300380228137\n",
            "for threshold 0.9 accuracy is =  0.40209125475285173\n",
            "for threshold 0.8 accuracy is =  0.6739543726235742\n",
            "for threshold 0.7 accuracy is =  0.8830798479087453\n",
            "for threshold 0.6 accuracy is =  0.9771863117870723\n",
            "for threshold 0.5 accuracy is =  0.9980988593155894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP2vrgAA1Ivc",
        "outputId": "a334b6d5-39f4-4ac0-caaa-ff241821ecb1"
      },
      "source": [
        "# printing overall train accuracy of model \n",
        "print(\"train Accuracy :\",metrics.accuracy_score(y_train, predictions_train))\n",
        "# printing overall test accuracy of model\n",
        "print(\"test Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
        "# printing hamming loss of  test data\n",
        "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
        "\n",
        "# printing micro precision of test data\n",
        "precision = precision_score(y_test, predictions, average='micro')\n",
        "# printing micro recall of test data\n",
        "recall = recall_score(y_test, predictions, average='micro')\n",
        "# printing micro f1-score of test data\n",
        "f1 = f1_score(y_test, predictions, average='micro')\n",
        " \n",
        "print(\"Micro-average quality numbers\")\n",
        "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
        "# printing macro precision of test data\n",
        "precision = precision_score(y_test, predictions, average='macro')\n",
        "# printing macro recall of test data\n",
        "recall = recall_score(y_test, predictions, average='macro')\n",
        "# printing macro f1-score of test data\n",
        "f1 = f1_score(y_test, predictions, average='macro')\n",
        " \n",
        "print(\"Macro-average quality numbers\")\n",
        "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Accuracy : 0.9155791190864601\n",
            "test Accuracy : 0.12167300380228137\n",
            "Hamming loss  0.1623891001267427\n",
            "Micro-average quality numbers\n",
            "Precision: 0.4998, Recall: 0.5051, F1-measure: 0.5024\n",
            "Macro-average quality numbers\n",
            "Precision: 0.4776, Recall: 0.4479, F1-measure: 0.4535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFMdYiN3FIlW"
      },
      "source": [
        "## saving model##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe1Y7Ai4bfji",
        "outputId": "b8cfd6f7-b5af-4de7-8c89-03f054844071"
      },
      "source": [
        "# saving the model using joblib\n",
        "joblib.dump(classifier , 'model.pkl')\n",
        "joblib.dump(vectorizer , 'vectorizer.pkl')"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-M9JvOabpU-"
      },
      "source": [
        "**Loading Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWdVIxWZbobr"
      },
      "source": [
        "# to map index with class name\n",
        "def print_class(arr):\n",
        "  cls_list = []\n",
        "  for index, value in enumerate(arr):\n",
        "    if value == 1:\n",
        "      cls_list.append(classes[index])\n",
        "  return cls_list\n",
        "   "
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LPk417Qbffv"
      },
      "source": [
        "# loading saved model\n",
        "# saving vectorizer as vect\n",
        "vect = joblib.load('vectorizer.pkl')\n",
        "# saving classifier as model\n",
        "model = joblib.load('model.pkl')"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmGkhnM4jw-N"
      },
      "source": [
        "# testing = 'any input text which is to be texted'"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6g_LPbFb3jT"
      },
      "source": [
        "# first encode input same as in trained model\n",
        "# v = vect.transform([testing])\n",
        "# predict with classifiers\n",
        "# p = model.predict(v)\n",
        "# mapping predicted value with classes\n",
        "# testing_result=print_class(p[0])"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JQqu52Fchha"
      },
      "source": [
        "**Storing Result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXmlXYvax8K-"
      },
      "source": [
        "def simlr(testing_result,true):\n",
        "  ''' it will compute how similar two lists are'''\n",
        "  count = 0\n",
        "  for i in true:\n",
        "    if i in testing_result:\n",
        "      count= count+1\n",
        "  return count/len(true)"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg5aV9ozkSom"
      },
      "source": [
        "# defininf data with four columns , initialised  with empty list\n",
        "d = {\n",
        "    \"Input\":[],\n",
        "     \"Prediction\":[],\n",
        "     \"true_result\":[],\n",
        "     \"similarity\":[],\n",
        "\n",
        "}"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61V0CLTRsHjy"
      },
      "source": [
        "# giving a rainge of values of i which will select that corresponding description and tags\n",
        "for i in range(3465,3473):\n",
        "  testing = data['description'][i]\n",
        "# encodig input text\n",
        "  v = vect.transform([testing])\n",
        "# predicting model\n",
        "  p = model.predict(v)\n",
        "  # mappin result with classes\n",
        "  testing_result=print_class(p[0])\n",
        "\n",
        "  # retriving real tags from dataset and splitting them bcz they string\n",
        "  true = data['tags'][i].split()\n",
        "\n",
        "# computing similarity between real tags and predicted tags\n",
        "  sm = simlr(testing_result,true)\n",
        "\n",
        "# appending calculated data in corresponding colun\n",
        "  d['Input'].append(testing)\n",
        "  d['Prediction'].append(testing_result)\n",
        "  d['true_result'].append(true)\n",
        "  d['similarity'].append(sm)"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7VdjqOwtqIw"
      },
      "source": [
        "# making dataframe\n",
        "x = pd.DataFrame(d)"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "drglsSWEkSjZ",
        "outputId": "1b1620fa-cf00-497f-b497-e34c7f057697"
      },
      "source": [
        "x"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>true_result</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We are seeking a fleet mechanic to keep autos,...</td>\n",
              "      <td>[2-4-years-experience-needed, 5-plus-years-exp...</td>\n",
              "      <td>[2-4-years-experience-needed, part-time-job]</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>We are recruiting dynamic professionals like y...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[salary]</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pharmaceutical Formulation Chemist   Responsib...</td>\n",
              "      <td>[2-4-years-experience-needed, bs-degree-needed]</td>\n",
              "      <td>[bs-degree-needed, 1-year-experience-needed]</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Please email resume and/or cover letter first....</td>\n",
              "      <td>[]</td>\n",
              "      <td>[supervising-job]</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A partially paralyzed man in Madison requires ...</td>\n",
              "      <td>[part-time-job, salary]</td>\n",
              "      <td>[part-time-job]</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>We are looking for a PT Driver for our Fixed R...</td>\n",
              "      <td>[full-time-job, hourly-wage, part-time-job]</td>\n",
              "      <td>[hourly-wage, licence-needed, part-time-job]</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Registered Nurses needed for positions in Dall...</td>\n",
              "      <td>[2-4-years-experience-needed, licence-needed]</td>\n",
              "      <td>[licence-needed]</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Registered Nurses needed for *acute care* posi...</td>\n",
              "      <td>[2-4-years-experience-needed, licence-needed]</td>\n",
              "      <td>[2-4-years-experience-needed, licence-needed, ...</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Input  ... similarity\n",
              "0  We are seeking a fleet mechanic to keep autos,...  ...   0.500000\n",
              "1  We are recruiting dynamic professionals like y...  ...   0.000000\n",
              "2  Pharmaceutical Formulation Chemist   Responsib...  ...   0.500000\n",
              "3  Please email resume and/or cover letter first....  ...   0.000000\n",
              "4  A partially paralyzed man in Madison requires ...  ...   1.000000\n",
              "5  We are looking for a PT Driver for our Fixed R...  ...   0.666667\n",
              "6  Registered Nurses needed for positions in Dall...  ...   1.000000\n",
              "7  Registered Nurses needed for *acute care* posi...  ...   0.666667\n",
              "\n",
              "[8 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNgO8-NSmvlQ"
      },
      "source": [
        "# storing dataframe into csv file named result.csv\n",
        "x.to_csv('result.csv',index=False)"
      ],
      "execution_count": 196,
      "outputs": []
    }
  ]
}